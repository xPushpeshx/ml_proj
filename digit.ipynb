{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ..., 10.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ..., 16.,  9.,  0.],\n",
       "        ...,\n",
       "        [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "        [ 0.,  0.,  2., ..., 12.,  0.,  0.],\n",
       "        [ 0.,  0., 10., ..., 12.,  1.,  0.]]),\n",
       " 'target': array([0, 1, 2, ..., 8, 9, 8]),\n",
       " 'frame': None,\n",
       " 'feature_names': ['pixel_0_0',\n",
       "  'pixel_0_1',\n",
       "  'pixel_0_2',\n",
       "  'pixel_0_3',\n",
       "  'pixel_0_4',\n",
       "  'pixel_0_5',\n",
       "  'pixel_0_6',\n",
       "  'pixel_0_7',\n",
       "  'pixel_1_0',\n",
       "  'pixel_1_1',\n",
       "  'pixel_1_2',\n",
       "  'pixel_1_3',\n",
       "  'pixel_1_4',\n",
       "  'pixel_1_5',\n",
       "  'pixel_1_6',\n",
       "  'pixel_1_7',\n",
       "  'pixel_2_0',\n",
       "  'pixel_2_1',\n",
       "  'pixel_2_2',\n",
       "  'pixel_2_3',\n",
       "  'pixel_2_4',\n",
       "  'pixel_2_5',\n",
       "  'pixel_2_6',\n",
       "  'pixel_2_7',\n",
       "  'pixel_3_0',\n",
       "  'pixel_3_1',\n",
       "  'pixel_3_2',\n",
       "  'pixel_3_3',\n",
       "  'pixel_3_4',\n",
       "  'pixel_3_5',\n",
       "  'pixel_3_6',\n",
       "  'pixel_3_7',\n",
       "  'pixel_4_0',\n",
       "  'pixel_4_1',\n",
       "  'pixel_4_2',\n",
       "  'pixel_4_3',\n",
       "  'pixel_4_4',\n",
       "  'pixel_4_5',\n",
       "  'pixel_4_6',\n",
       "  'pixel_4_7',\n",
       "  'pixel_5_0',\n",
       "  'pixel_5_1',\n",
       "  'pixel_5_2',\n",
       "  'pixel_5_3',\n",
       "  'pixel_5_4',\n",
       "  'pixel_5_5',\n",
       "  'pixel_5_6',\n",
       "  'pixel_5_7',\n",
       "  'pixel_6_0',\n",
       "  'pixel_6_1',\n",
       "  'pixel_6_2',\n",
       "  'pixel_6_3',\n",
       "  'pixel_6_4',\n",
       "  'pixel_6_5',\n",
       "  'pixel_6_6',\n",
       "  'pixel_6_7',\n",
       "  'pixel_7_0',\n",
       "  'pixel_7_1',\n",
       "  'pixel_7_2',\n",
       "  'pixel_7_3',\n",
       "  'pixel_7_4',\n",
       "  'pixel_7_5',\n",
       "  'pixel_7_6',\n",
       "  'pixel_7_7'],\n",
       " 'target_names': array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]),\n",
       " 'images': array([[[ 0.,  0.,  5., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  0., 13., ..., 15.,  5.,  0.],\n",
       "         [ 0.,  3., 15., ..., 11.,  8.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  4., 11., ..., 12.,  7.,  0.],\n",
       "         [ 0.,  2., 14., ..., 12.,  0.,  0.],\n",
       "         [ 0.,  0.,  6., ...,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0., ...,  5.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  9.,  0.,  0.],\n",
       "         [ 0.,  0.,  3., ...,  6.,  0.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "         [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ..., 10.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0., ..., 12.,  0.,  0.],\n",
       "         [ 0.,  0.,  3., ..., 14.,  0.,  0.],\n",
       "         [ 0.,  0.,  8., ..., 16.,  0.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  9., 16., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  3., 13., ..., 11.,  5.,  0.],\n",
       "         [ 0.,  0.,  0., ..., 16.,  9.,  0.]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0.,  0.,  1., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  0., 13., ...,  2.,  1.,  0.],\n",
       "         [ 0.,  0., 16., ..., 16.,  5.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  0., 16., ..., 15.,  0.,  0.],\n",
       "         [ 0.,  0., 15., ..., 16.,  0.,  0.],\n",
       "         [ 0.,  0.,  2., ...,  6.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  2., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0., 14., ..., 15.,  1.,  0.],\n",
       "         [ 0.,  4., 16., ..., 16.,  7.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  0.,  0., ..., 16.,  2.,  0.],\n",
       "         [ 0.,  0.,  4., ..., 16.,  2.,  0.],\n",
       "         [ 0.,  0.,  5., ..., 12.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0., 10., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  2., 16., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  0., 15., ..., 15.,  0.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  4., 16., ..., 16.,  6.,  0.],\n",
       "         [ 0.,  8., 16., ..., 16.,  8.,  0.],\n",
       "         [ 0.,  1.,  8., ..., 12.,  1.,  0.]]]),\n",
       " 'DESCR': \".. _digits_dataset:\\n\\nOptical recognition of handwritten digits dataset\\n--------------------------------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 1797\\n    :Number of Attributes: 64\\n    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\\n    :Missing Attribute Values: None\\n    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\\n    :Date: July; 1998\\n\\nThis is a copy of the test set of the UCI ML hand-written digits datasets\\nhttps://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\\n\\nThe data set contains images of hand-written digits: 10 classes where\\neach class refers to a digit.\\n\\nPreprocessing programs made available by NIST were used to extract\\nnormalized bitmaps of handwritten digits from a preprinted form. From a\\ntotal of 43 people, 30 contributed to the training set and different 13\\nto the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\\n4x4 and the number of on pixels are counted in each block. This generates\\nan input matrix of 8x8 where each element is an integer in the range\\n0..16. This reduces dimensionality and gives invariance to small\\ndistortions.\\n\\nFor info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\\nT. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\\nL. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\\n1994.\\n\\n.. topic:: References\\n\\n  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\\n    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\\n    Graduate Studies in Science and Engineering, Bogazici University.\\n  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\\n  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\\n    Linear dimensionalityreduction using relevance weighted LDA. School of\\n    Electrical and Electronic Engineering Nanyang Technological University.\\n    2005.\\n  - Claudio Gentile. A New Approximate Maximal Margin Classification\\n    Algorithm. NIPS. 2000.\\n\"}"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "data=datasets.load_digits()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797,)\n",
      "[0 1 2 ... 8 9 8]\n",
      "[[ 0.  0.  5. 13.  9.  1.  0.  0.]\n",
      " [ 0.  0. 13. 15. 10. 15.  5.  0.]\n",
      " [ 0.  3. 15.  2.  0. 11.  8.  0.]\n",
      " [ 0.  4. 12.  0.  0.  8.  8.  0.]\n",
      " [ 0.  5.  8.  0.  0.  9.  8.  0.]\n",
      " [ 0.  4. 11.  0.  1. 12.  7.  0.]\n",
      " [ 0.  2. 14.  5. 10. 12.  0.  0.]\n",
      " [ 0.  0.  6. 13. 10.  0.  0.  0.]]\n",
      "(8, 8)\n",
      "['pixel_0_0', 'pixel_0_1', 'pixel_0_2', 'pixel_0_3', 'pixel_0_4', 'pixel_0_5', 'pixel_0_6', 'pixel_0_7', 'pixel_1_0', 'pixel_1_1', 'pixel_1_2', 'pixel_1_3', 'pixel_1_4', 'pixel_1_5', 'pixel_1_6', 'pixel_1_7', 'pixel_2_0', 'pixel_2_1', 'pixel_2_2', 'pixel_2_3', 'pixel_2_4', 'pixel_2_5', 'pixel_2_6', 'pixel_2_7', 'pixel_3_0', 'pixel_3_1', 'pixel_3_2', 'pixel_3_3', 'pixel_3_4', 'pixel_3_5', 'pixel_3_6', 'pixel_3_7', 'pixel_4_0', 'pixel_4_1', 'pixel_4_2', 'pixel_4_3', 'pixel_4_4', 'pixel_4_5', 'pixel_4_6', 'pixel_4_7', 'pixel_5_0', 'pixel_5_1', 'pixel_5_2', 'pixel_5_3', 'pixel_5_4', 'pixel_5_5', 'pixel_5_6', 'pixel_5_7', 'pixel_6_0', 'pixel_6_1', 'pixel_6_2', 'pixel_6_3', 'pixel_6_4', 'pixel_6_5', 'pixel_6_6', 'pixel_6_7', 'pixel_7_0', 'pixel_7_1', 'pixel_7_2', 'pixel_7_3', 'pixel_7_4', 'pixel_7_5', 'pixel_7_6', 'pixel_7_7']\n"
     ]
    }
   ],
   "source": [
    "print(data.target.shape)\n",
    "print(data.target)\n",
    "print(data.images[0])\n",
    "print(data.images[0].shape)\n",
    "print(data.feature_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 [[ 0.  0.  8. 16.  5.  0.  0.  0.]\n",
      " [ 0.  1. 13. 11. 16.  0.  0.  0.]\n",
      " [ 0.  0. 10.  0. 13.  3.  0.  0.]\n",
      " [ 0.  0.  3.  1. 16.  1.  0.  0.]\n",
      " [ 0.  0.  0.  9. 12.  0.  0.  0.]\n",
      " [ 0.  0.  3. 15.  5.  0.  0.  0.]\n",
      " [ 0.  0. 14. 15.  8.  8.  3.  0.]\n",
      " [ 0.  0.  7. 12. 12. 12. 13.  1.]]\n"
     ]
    }
   ],
   "source": [
    "x=data.images\n",
    "y=data.target\n",
    "print(y[22],x[22])\n",
    "y=tf.keras.utils.to_categorical(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(9):  \n",
    "    plt.subplot(330 + 1 + i)\n",
    "    plt.imshow(x[i], cmap=plt.get_cmap('gray'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model():\n",
    "    model=Sequential([\n",
    "        Conv2D(32,(3,3),activation='relu',input_shape=(8,8,1)),\n",
    "        MaxPool2D((2,2)),\n",
    "        Flatten(),\n",
    "        Dense(64,activation='relu'),\n",
    "        Dense(10,activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_17 (Conv2D)          (None, 6, 6, 32)          320       \n",
      "                                                                 \n",
      " max_pooling2d_17 (MaxPoolin  (None, 3, 3, 32)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_16 (Flatten)        (None, 288)               0         \n",
      "                                                                 \n",
      " dense_38 (Dense)            (None, 64)                18496     \n",
      "                                                                 \n",
      " dense_39 (Dense)            (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19,466\n",
      "Trainable params: 19,466\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=make_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.] [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "x_train=x[:1000]\n",
    "y_train=y[:1000]\n",
    "x_test=x[1000:]\n",
    "y_test=y[1000:]\n",
    "print(y_train[2],y_train[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1056 - accuracy: 0.9800 - val_loss: 0.2242 - val_accuracy: 0.9335\n",
      "Epoch 2/10\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0923 - accuracy: 0.9830 - val_loss: 0.2230 - val_accuracy: 0.9360\n",
      "Epoch 3/10\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0804 - accuracy: 0.9870 - val_loss: 0.2055 - val_accuracy: 0.9360\n",
      "Epoch 4/10\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0683 - accuracy: 0.9890 - val_loss: 0.1985 - val_accuracy: 0.9473\n",
      "Epoch 5/10\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0608 - accuracy: 0.9940 - val_loss: 0.2031 - val_accuracy: 0.9398\n",
      "Epoch 6/10\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0528 - accuracy: 0.9970 - val_loss: 0.1935 - val_accuracy: 0.9473\n",
      "Epoch 7/10\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 0.0482 - accuracy: 0.9960 - val_loss: 0.1834 - val_accuracy: 0.9460\n",
      "Epoch 8/10\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0429 - accuracy: 0.9980 - val_loss: 0.1916 - val_accuracy: 0.9460\n",
      "Epoch 9/10\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0399 - accuracy: 0.9990 - val_loss: 0.1805 - val_accuracy: 0.9523\n",
      "Epoch 10/10\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0361 - accuracy: 0.9980 - val_loss: 0.1736 - val_accuracy: 0.9536\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(x_train,y_train,epochs=10,validation_data=(x_test,y_test),batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "y_pred=model.predict(x_test)\n",
    "y_pred\n",
    "y_pred_n=np.argmax(y_pred,axis=1)\n",
    "y_pred_new=tf.keras.utils.to_categorical(y_pred_n)\n",
    "y_pred_new[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98        76\n",
      "           1       0.89      1.00      0.94        71\n",
      "           2       0.96      0.96      0.96        77\n",
      "           3       0.86      0.96      0.91        71\n",
      "           4       0.94      0.97      0.96        80\n",
      "           5       0.98      0.96      0.97        83\n",
      "           6       1.00      0.99      0.99        81\n",
      "           7       0.97      0.99      0.98        79\n",
      "           8       1.00      0.89      0.94        85\n",
      "           9       0.98      0.84      0.90        94\n",
      "\n",
      "   micro avg       0.95      0.95      0.95       797\n",
      "   macro avg       0.95      0.96      0.95       797\n",
      "weighted avg       0.96      0.95      0.95       797\n",
      " samples avg       0.95      0.95      0.95       797\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_pred_new,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
